---
chapter: 3
knit: "bookdown::render_book"
---


# Empirical Results

## Pure time series setting (S\&P 500)  

Reconsidering the example in Section 3 of @GA11, the data we use is the daily Standard and Poor's (S\&P) 500 index from February 11, 2013 to February 10, 2023 (10 years in total), retrieved from the @SP500. The S&P500 index dataset has a total of 2519 ($T$) observations and is partitioned into two periods with a rough proportion. The in-sample period contains the first 60% of the data ($R = 1511$), which is used to estimate all unknown parameters, including the optimal weight. The remaining 40% ($P = 1008$) becomes the out-of-sample period to evaluate the forecast performance.  

We will investigate the presence of the forecast combination puzzle when fitting the nonstationary data and the stationary data. Constituent models come from commonly used model types, which are autoregressive integrated moving average (ARIMA), exponential smoothing (ETS), and linear regression model with ARIMA errors. Detailed model specifications for each case will be clarified in the corresponding section.  

To start with, 

We choose $j=1,\cdots,M$, with $M=3$ prediction models to study the performance of density predictions across sets of ``two-model`` pools. Each of the $j$ predictive model has a conditional Gaussian density, which takes the form $f^{(j)}(y)=f_j(y_t|\mathcal{F}_{t-1})=N\{y_t; \mu_j, \sigma^2_j\}$, where $N\{x; \mu, \sigma^2\}$ denotes the normal probability density function evaluated at value $x$ with mean $\mu$ and variance $\sigma^2$. The notation $\mathcal{F}_{t-1}$ denotes all information available at time $t-1$, and we assume that the conditional mean and variance of the models are, up to unknown parameters, known at time $t-1$.



### Fitting the nonstationary time series

To reduce the level of variability, we take a natural logarithm of the S\&P 500 index and fit three candidate models directly without removing its stochastic trend.

1. Model 1: ARIMA(1,1,1) model with an intercept of the natural logarithm of S\&P 500 index. 
\begin{equation*}
log(y_t) = c + log(y_{t-1}) + \phi_1\big[log(y_{t-1})-log(y_{t-2})\big] + \epsilon_t + \theta_1\epsilon_{t-1}
\end{equation*}

2. Model 2: ETS(M,N,N) model of the natural logarithm of S\&P 500 index. 
\begin{align*}
log(y_t) &= \ell_{t-1} (1+\epsilon_t) \\
\ell_t &= \ell_{t-1} (1+\alpha \epsilon_t) \\
\end{align*}

3. Model 3: A linear regression model of the natural logarithm of the S\&P 500 index and ARIMA(1,0,0) errors. 
\begin{align*}
log(y_t) &= \beta_0 + \beta_1 t + u_t \\
u_t &= \phi_1 u_{t-1} + \epsilon_t
\end{align*}

The error term, $\epsilon_t$, in each model is assumed to be independent and normally distributed with a zero mean and a constant variance.  


\begin{table}[ht]
  \centering
  \caption{Log predictive score of density forecasts combination under two-model pools}
    \begin{tabular}{llllll}
    \toprule
          & ARIMA(1,1,1) & ETS(M,N,N) & LR \\
    \midrule
    ARIMA(1,1,1) & \textit{-5911.1974} & -5839.3045 & -5842.7634 \\
    ETS(M,N,N) & 0.45  & \textit{-5883.9697} & -5881.7790 \\
    LR & 0.43  & 0.08  & \textit{-5881.7970} \\
    \bottomrule
    \multicolumn{4}{l}{\footnotesize The diagonal entries contains individual log score.}\\
    \multicolumn{4}{l}{\footnotesize The log scores for combination pools are located above the diagonal.}\\
    \multicolumn{4}{l}{\footnotesize Entries below diagonal show the estimated weight of the model in that column in the two-model pool.}\\
    \end{tabular}
  \label{tab:2}
\end{table}

There are 3 sets of two-model combination and the log predictive score of each combination is generated according to \ref{eqn:LS} with the value of weight changing by 0.01 every time. Table \ref{tab:2} shows the estimated weights and combination log scores. 



We focused on the combination of two individual forecasts for two reasons, which in most cases apply for the prediction of business figures in enterprises. Typically, a judgmental forecast and one that is derived using purely statistical means are available and corporate planning can be based on one of the forecast or a combination of both forecasts, where additional forecasts cannot be expected to introduce as much additional information. Furthermore, focusing on the two-forecast case allowed us to provide a variety of in-depth analyses. The challenge of extending the model and the decision boundaries to a larger, arbitrary number of forecasts is subject to future research.




All unknown parameters are estimated by maximizing the likelihood function using the in-sample period data. Once the estimated are obtained, they are held fixed for the density evaluations. For each model, I generate the predictive densities at every future time point of S&P 500 returns ($h=1,2,...,P$) given that all past information is known. In order to make a comparison between each pair of these models, the log of S&P 500 returns will be "back-transformed" by evaluating with the log normal density function.








### Fitting the stationary time series
















