---
chapter: 3
knit: "bookdown::render_book"
---


# Empirical Results

## Daily time series (S\&P 500) {#sp500}

Reconsidering the example in Section 3 of @GA11, the data we use is the daily Standard and Poor's (S\&P) 500 index from February 11, 2013 to February 10, 2023 (10 years in total), retrieved from Federal Reserve Economic Data [@SP500]. The S&P 500 index dataset has $T = 2519$ total observations and is partitioned into two periods with a rough proportion. The in-sample period contains the first 60% of the data ($R = 1511$), which is used to estimate all unknown parameters, including the optimal weight. The remaining 40% ($P = 1008$) is reserved to evaluate forecast performance.  

We will investigate the presence of the forecast combination puzzle when both models fit the training set well and when one model badly fits the data. Three predictive models are chosen to study the performance of density predictions across sets of two-model pools from common classes of linear time series models: autoregressive integrated moving average (ARIMA), exponential smoothing (ETS), and linear regression model with ARIMA errors (LR). Detailed model specifications are elaborated in the Appendix. 

We use $P(A_1, A_2; \omega_{opt})$ to denote a two-model pool, where $A_1$ and $A_2$ are constituent models in the pool and $\omega_{opt}$ is the optimal weight assigned to the first model $A_1$. 



\subsection*{Nonstationary time series}

To reduce the level of variability, we take a natural logarithm of the S\&P 500 index. Three candidate models are proposed to fit the log of the index, resulting in three sets of two-model combinations in total. The weight $\omega$ takes values on a grid from 0 to 1 with increment of 0.01. The log score, as a function of the weight $\omega$, is generated to search for the optimal weight over the in-sample period (refer to the top row of Figure \ref{fig:nonstat}). According to equation (\ref{eqn:LS2}), the estimated optimal weight corresponds to the maximum point of the curve. Then we can calculate the log predictive score of the optimal combination for the out-of-sample period based on equation (\ref{eqn:LS3}).

\begin{figure}[ht]
\centering
\includegraphics[scale=0.45]{figures/SP500_nonstationary.pdf}
\caption{Log predictive score of S\&P 500 index predictive densities in two-model pools over the in-sample (top) and out-of-sample (bottom) period. Constituent prediction models are described in the title with `P` representing `Pool`. The x-axis represents the weight assigned on the former model of the combination and the y-axis indicates the log predictive score. The orange dot represents the optimal combination, while the blue dot indicates the simple average.}
\label{fig:nonstat}
\end{figure}

Figure \ref{fig:nonstat} suggests that the forecast combination puzzle is evidenced in all three cases, i.e., the simple average performs better than the optimal combination. It is noticeable that the accuracy differences are different. For example, the accuracy difference in P(ARIMA,LR; 0.41) is much smaller than that in other two pools. This is tightly related to the in-sample fit of the constituent models, which can be represented by the log likelihood value. Table \ref{tab:nonfit} illustrates the log likelihood values of constituent models in each pool and the absolute difference. 

One explanation for the poor performance of the ETS(M,N,N) model could be that it fails to capture the trend component, as shown in Figure \ref{fig:llg}. Compared with ARIMA and linear regression, the ETS model fits the training set poorly, making it a relatively ``Bad`` model in two-model pools as a consequence.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/log_linegraph.pdf}
\caption{The black vertical line separates the traning set and the evaluation set. The training set is on the left and the evaluation set is on the right.}
\label{fig:llg}
\end{figure}

Linking it with our preliminary conjecture in Table \ref{tab:1}, P(ARIMA,ETS; 0.65) can be viewed as a (B,G) case where the ARIMA model has a much better in-sample fit than the ETS mode. Similarly, we have a (G,B) case for P(ETS,LR; 0.21) since the LR model performs much better than the ETS model. P(ARIMA,LR; 0.41), on the other hand, exemplifies a (G,G) case since two models fit the in-sample data well.

\begin{table}[ht]
  \centering
    \begin{tabular}{l|ccc}
    \toprule
                                    & P(ARIMA,ETS; 0.65) & P(ARIMA,LR; 0.41) & P(ETS,LR; 0.21) \\  
    \midrule
    First Model Log Likelihood      &     5113.694       &      5113.694     &   1725.137      \\
    Second Model Log Likelihood     &     1725.137       &      5116.014     &   5116.014      \\
    Log Likelihood Difference       &     3388.556       &       2.320       &   3390.876      \\
    Type                            &       (G,B)        &       (G,G)       &     (B,G)       \\
    Presence of the puzzle          &       Yes          &        Yes        &     Yes         \\
    \bottomrule
    \end{tabular}
  \caption{``Log Likelihood Difference`` represents the absolute difference of in-sample fit between two models, which is evaluated by the log likelihood. ``Type`` refers to the case of each two-model pool in the conjecture table. ``Presence of the puzzle`` indicates whether the simple average is close to or outperforms the optimal forecast combination.}
  \label{tab:nonfit}
\end{table}





\subsection*{Stationary time series}

Continuing with the same dataset, we now take a first difference of the log of S\&P 500 index, to construct log-returns, and then fit this series, which is covariance stationary. A series is said to be covariance stationary when it has constant mean and variance, and the covariance between two observations at different time points depends on their time interval only.

Two candidate models are automatically selected by the `ARIMA()` function in the fable package [@fpp23]: a Gaussian ARMA(1,1) model and a linear regression model with ARMA(1,1) errors. To differentiate with the first LR model, the second model is named as Linear Regression 2 (LR2) in the pool. Figure \ref{fig:stat} illustrates that two constituent models have a very similar in-sample log score with only 0.0011 difference, and the puzzle is evidenced by the only 0.1282 accuracy difference between two forecast combination approaches. Strictly speaking, the forecast accuracy of the optimally-weighted combination (2349.764) is slightly superior to that of equally-weighted combination (2349.636). However, this difference in forecast accuracy is so small as to make no real difference in practice. In addition, using equal weights is much more efficient than estimating optimal weights through any weighting scheme. Recall that our definition of the forecast combination puzzle are cases where 1) the simple average performs much better out-of-sample than the optimal combination; and 2) the forecast accuracy of the two methods is similar. Comparing the log likelihood of two models in Table \ref{tab:statfit}, the similar in-sample performance is another evidence of having a (G,G) case with the puzzle in evidence.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.6]{figures/SP500_stationary.pdf}
\caption{Log predictive score of S\&P 500 log returns predictive densities in two-model pools over the in-sample (left) and the out-of-sample (right) period. The x-axis represents the weight assigned on the ARMA(1,1) model and the y-axis indicates the log predictive score. The meanings of colored dots remain the same as before.}
\label{fig:stat}
\end{figure}

\begin{table}[ht]
  \centering
    \begin{tabular}{l|ccc}
    \toprule
                                    &     P(ARMA,LR2;0.69)    \\  
    \midrule
    First Model Log Likelihood      &         5109.8071       \\
    Second Model Log Likelihood     &         5109.8054       \\
    Log Likelihood Difference       &          0.0016         \\
    Type                            &          (G,G)          \\
    Presence of the puzzle          &           Yes           \\
    \bottomrule
    \end{tabular}
  \caption{``Log Likelihood Difference`` represents the absolute difference of in-sample fit between two models, which is evaluated by the log likelihood. ``Type`` refers to the case of two models in the conjecture table. ``Presence of the puzzle`` indicates whether the simple average is close to or outperforms the optimal forecast combination.}
  \label{tab:statfit}
\end{table}

This Section \@ref(sp500) provides some empirical evidence for our initial conjecture. When both models fit the data well, i.e., they are ``Good`` models, then the accuracy of the optimal density forecast combination is close to that of the average density forecast, indicating the presence of the forecast combination puzzle. If one model is ``Bad`` and the other is ``Good``, then, at least, the puzzle can be evidenced.



## Seasonal time series

With the purpose of further examining our conjecture as to when the puzzle will be in evidence, we now use a quarterly dataset to explore the relationship between the forecast combination puzzle and in-sample model fit. More specifically, we investigate cases where both models are both well-specified (good in-sample fit) or poorly-specified (poor in-sample fit). To simplify the analysis, we produce point forecasts and evaluate point combinations with MSFE.

The data considered is the recorded quarterly total number of unemployed individuals (in thousands) from 1985 Q1 to 2023 Q1, retrieved from the Australia Bureau of Statistics [@ABS]. We use the natural logarithm of the total number of unemployment to reduce the level of variability in the series.

It has $T = 153$ total observations and is slit into two sets in proportion. As before, the first 60% of the data ($R = 91$), as the in-sample period, is used to estimate all unknown parameters. The remaining 40% ($P = 62$) is the out-of-sample period reserved for forecast performance evaluation.



\subsection*{Well-specified models}

To ensure compatibility with seasonal component, we propose the Seasonal ARIMA (SARIMA) model and the ETS model: ARIMA(2,0,2)(0,1,1)[4] with drift and ETS(A,A,A). The SARIMA is simply an ARIMA model with extra seasonal component. The first parenthesis is same as the ARIMA model. The second parenthesis represents the seasonal AR, integrated, and MA components respectively, separately by the comma. The number in the box bracket indicates the number of observations per year, i.e., the seasonal frequency. An intercept is included in the model. In the ETS model, the seasonal part is reflected by `S` and the third position in the parenthesis. Due to the log transformation, we have additive error, additive trend, and additive seasonality.

The forecast combination puzzle is evidenced in Figure \ref{fig:sd}; the accuracy difference between two combinations is negligible. The optimally-weighted point combination has a MSFE of 0.000177 and the equally-weighted forecast has a MSFE of 0.000178. Looking at the in-sample combination plot, two models fit the training set equally well, which can also be confirmed by the second column of Table \ref{tab:season}.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/EMPL.pdf}
\caption{MSFE of predictive number of unemploymed people in well-specified (left) and pooly-specified (right) two-model pools over the in-sample (top) and out-of-sample (bottom) period. The x-axis represents the weight assigned on the first model and the y-axis indicates the value of MSFE. The meanings of colored dots remain the same.}
\label{fig:sd}
\end{figure}





\subsection*{Poorly-specified models}

One way of proposing a ``Bad`` model for a seasonal dataset is to deliberately ignore the seasonality in data. In this section, we consider the ARIMA(2,1,0) and ETS(A,A,N) models, which do not capture any seasonal component and are the best models automatically selected by `ARIMA` and `ETS` functions in R.

\begin{table}[ht]
  \centering
    \begin{tabular}{l|ccc}
    \toprule
                                      &   P(SARIMA,ETS;0.52)   &   P(ARIMA,ETS;0.87)  \\  
    \midrule
    First Model Log Likelihood        &         321.4497       &      322.1642        \\
    Second Model Log Likelihood       &         260.9102       &      231.9507        \\
    Log Likelihood Difference         &         60.5395        &      90.2135         \\
    Type                              &          (G,G)         &       (B,B)          \\
    Presence of the puzzle            &           Yes          &        Yes           \\
    \bottomrule
    \end{tabular}
  \caption{``Log Likelihood Difference`` represents the absolute difference of in-sample fit between two models, which is evaluated by the log likelihood. ``Type`` refers to the case of two models in the conjecture table. ``Presence of the puzzle`` indicates whether the simple average is close to or outperforms the optimal forecast combination.}
  \label{tab:season}
\end{table}

The right column of Figure \ref{fig:sd} does reveal the forecast combination puzzle, as the equally-weighted combination performs better than the optimally-weighted forecast combination. Furthermore, the third column of Table \ref{tab:season} illustrates that both models have similar log likelihood. We may claim that, regardless of whether the constituent models capture all the features of the data, as long as they have similar in-sample performance, the forecast combination puzzle will be evidenced. As a result, we should also expect to find the puzzle if two models are equally ``Bad``.

The empirical evidence suggest that the puzzle is in evidence in all cases, however, these examples are not enough to draw comprehensive conclusions. Also, one big challenge of working with empirical data is that the true DGP is unknown. 

To partially circumvent these issues, we use a simulation experiment based on a pure cross-sectional process to further investigate when the optimal forecast combination is more accurate than the simple averaging. Compared with simulated time series data, there is no need to consider the dependence of observations, hence, is an easy starting point. As an additional contribution, it examines the presence of the forecast combination puzzle in the cross-sectional setting.




