---
title: "Backup"
author: "Sapphire"
date: "2023-07-26"
output: pdf_document
---

\begin{figure}[ht]
\centering
\includegraphics[scale=0.35]{figures/Sample_Size_100-10000.png}
\caption{Three columns refer to cases when $N=100$, $N=1000$, and $N=10000$ respectively while keeping all others constant as the initial set-up. The top graphs represent the in-sample combination performance and the bottom graphs represent the out-of-sample combination accuracy. The meanings of colored dots are the same as those in Figure \ref{fig:ss1000}.}
\label{fig:ss}
\end{figure}


\begin{table}[ht]
  \centering
    \begin{tabular}{l|ccc}
    \toprule
    Sample Size              &   $N=50$    &    $N=100$   &  $N=1000$  \\
    \midrule
    Partial $R^2$ of $M_1$   &   0.1756    &    0.0015    &   0.1203   \\
    Partial $R^2$ of $M_2$   &   0.0453    &    0.2456    &   0.1049   \\
    Difference               &   0.1303    &    0.2441    &   0.0154   \\
    Combination              &     BG      &      GB      &     BB     \\
    Optimal Weight           &    0.07     &     0.98     &    0.48    \\
    Puzzle                   &    Yes      &     Yes      &    Yes     \\
    \bottomrule
    \end{tabular}
  \caption{}
  \label{tab:samplesize}
\end{table}



\begin{table}[ht]
  \centering
    \begin{tabular}{l|cccc}
    \toprule
    Different Signs         &  $\beta_1=2,\ \beta_2=-2$  &  $\beta_1=4,\ \beta_2=-4$  &  $\beta_1=2,\ \beta_2=-2$  &  $\beta_1=4,\ \beta_2=-4$\\
    \midrule
    Partial $R^2$ of $M_1$  &           0.1222           &   0.3566   &    0.3307     &   0.5355   \\
    Partial $R^2$ of $M_2$  &           0.1049           &   0.3261   &    0.2456     &   0.4241   \\
    Difference              &           0.0173           &   0.0305   &    0.0851     &   0.1114   \\
    Combination             &             BB             &     BB     &      BG       &     BG     \\
    Optimal Weight          &            0.38            &    0.38    &     0.38      &     0      \\
    Puzzle                  &            Yes             &     Yes    &      No       &     No     \\
    Sample Size             &            1000            &    1000    &     100       &    100     \\
    \bottomrule
    \end{tabular}
  \caption{When the sample size is 1000}
  \label{tab:betasig}
\end{table}

\begin{table}[ht]
  \centering
    \begin{tabular}{l|cccc}
    \toprule
    Different Magnitudes    &  $\beta_1=2,\ \beta_2=4$   &  $\beta_1=2,\ \beta_2=6$ &  $\beta_1=2,\ \beta_2=4$  &  $\beta_1=2,\ \beta_2=6$  \\
    \midrule
    Partial $R^2$ of $M_1$  &           0.3546           &   0.5532   &    0.1434   &   0.5532   \\
    Partial $R^2$ of $M_2$  &           0.1049           &   0.1049   &    0.2456   &   0.1049   \\
    Difference              &           0.2497           &   0.4483   &    0.1022   &   0.4483   \\
    Combination             &             BG             &     BG     &      GB     &     GB     \\
    Optimal Weight          &            0.18            &    0.04    &     0.59    &    0.04    \\
    Puzzle                  &             No             &     No     &     Yes     &     No     \\
    Sample Size             &            1000            &    1000    &     100     &    100     \\
    \bottomrule
    \end{tabular}
  \caption{}
  \label{tab:betamag}
\end{table}


\begin{table}[ht]
  \centering
    \begin{tabular}{l|cccc}
    \toprule
    Change in Variance of $x_{1i}$    &  $Var(x_{1i}) = 2$   &  $Var(x_{1i}) = 4$  &  $Var(x_{1i}) = 2$  &  $Var(x_{1i}) = 4$  \\
    \midrule
    Partial $R^2$ of $M_1$  &       0.1665         &   0.1869   &    0.0276   &   0.0550   \\
    Partial $R^2$ of $M_2$  &       0.2595         &   0.4495   &    0.3685   &   0.5054   \\
    Difference              &       0.0930         &   0.2627   &    0.3410   &   0.4504   \\
    Combination             &         GB           &     BG     &      GB     &     GB     \\
    Optimal Weight          &        0.66          &    0.85    &     0.92    &    0.9     \\
    Puzzle                  &         No           &     No     &     Yes     &     Yes     \\
    Sample Size             &        1000          &    1000    &     100     &    100     \\
    \bottomrule
    \end{tabular}
  \caption{}
  \label{tab:xvar}
\end{table}


\begin{figure}[ht]
\centering
\includegraphics[scale=0.35]{figures/Beta_diff_mag.png}
\caption{In this case, $\beta_1$ and $\beta_2$ have the same sign but different magnitudes. The first column refers to $\beta_1=2$ and $\beta_2=3$, the second column refers to $\beta_1=2$ and $\beta_2=4$, and the third column refers to $\beta_1=2$ and $\beta_2=6$. Other variables remain unchanged as in the initial set-up.}
\label{fig:magnitude}
\end{figure}

Based on the results shown in Figure \ref{fig:magnitude}, the puzzle is highly sensitive to the absolute difference between two parameters. If the absolute difference is large enough, generally more than half of the smaller coefficient, it is hard to find the puzzle and the optimal combination always wins with a higher log predictive score. In the linear regression analysis, the magnitude of each coefficient represents the influence size of each regressor on the dependent variable. A large coefficient means that a change in the corresponding regressor affects the dependent variable more in magnitude. Knowing this, it is reasonable to observe that the Model 1 has a decreasing weight in the optimal combination from left to right in Figure \ref{fig:magnitude}. The effect of $x_{2i}$ on $y_i$, $\beta_2$, is relatively larger than the effect of $x_{1i}$ on $y_i$, $\beta_1$, so the Model 2 with $x_{2i}$ should be weighted higher in the combination.


\begin{figure}
\includegraphics[width=0.47\textwidth]{figures/betamag1.pdf}
\hspace{\fill}
\includegraphics[width=0.47\textwidth]{figures/betamag2.pdf}
\caption{}
\label{fig:samplesize}
\end{figure}

\begin{figure}
\includegraphics[width=0.47\textwidth]{figures/betamag3.pdf}
\hspace{\fill}
\includegraphics[width=0.47\textwidth]{figures/betamag4.pdf}
\caption{}
\label{fig:samplesize}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[scale=0.55]{figures/Beta_diff_sign.png}
\caption{$\beta_1$ and $\beta_2$ have the same magnitude but different signs, i.e. $\beta_1=-\beta_2$. The first column considers the case when $\beta_1=2$ and $\beta_2=-2$ and the second column considers the case when $\beta_1=4$ and $\beta_2=-4$. Other variables remain unchanged as in the initial set-up.}
\label{fig:sign}
\end{figure}

Figure \ref{fig:magnitude} illustrate that when $\beta_1$ and $\beta_2$ only have opposite signs, the puzzle tends to be insensitive. In both cases, the optimal combination and simple averaging forecast have very similar log predictive scores, which is a strong evidence for the presence of the puzzle. Meanwhile, two regressors have the same effect in magnitude on $y_i$, therefore, the weight is expected to be around 0.5.


\begin{figure}[ht]
\centering
\includegraphics[scale=0.55]{figures/x_var.png}
\caption{The first column refers to the case when $Var(x_{1i}) = 2$ and $Var(x_{2i}) = 1$. The second column refers to the case when $Var(x_{1i}) = 4$ and $Var(x_{2i}) = 1$.}
\label{fig:xvar}
\end{figure}

First thing noted from Figure \ref{fig:xvar} is that there is no forecast combination puzzle when the variances of two regressors are different. 









