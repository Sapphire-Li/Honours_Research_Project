level[j+1] <- level[j]*(1 + fit_2_coef[1,2]*resid_2[j,1])
}
# Residuals from R+1 to T (P in total)
resid_2_new <- numeric(P) |> as.numeric()
for(i in 1:P) {
resid_2_new[i] <- (test[i,2] - level[R+i]) / level[R+i]
level[R+i+1] <- level[R+i]*(1 + fit_2_coef[1,2]*resid_2_new[i])
}
# Conditional Mean for SP500
mean_2 <- numeric(P) |> as.numeric()
for (j in 1:P) {
mean_2[j] <- level[[R+j]]
}
mean_2 <- as_tibble(mean_2)
# Conditional Variance for SP500
# The full prediction density can be estimated using a kernel density estimator (Silverman 1986) applied to yn+h|n.
# The forecast variance is given by
var_2 <- glance(fit_2) |> select(sigma2) |> as.numeric()
var_2 <- mean_2^2*var_2
sd_2 <- sqrt(var_2)
# Predictive Density
pd_2 <- numeric(P) |> as.numeric()
for (j in 1:P) {
pd_2[j] <- dnorm(test[[j,2]], mean_2[[j,1]], sd_2[[j,1]])
}
LS_2 <- sum(log(pd_2)) / P
LS_2
# -5.837271
train |>
model(STL(SP500 ~ trend(window = 7),
robust = TRUE)) |>
components() |> autoplot()
# Model: ETS(M,A,N)
fit_3 <- train |> model(ETS(SP500 ~ error("M") + trend("A") + season("N")))
report(fit_3)
# Smoothing parameters:
#   alpha = 0.9727122
#   beta  = 0.0001000545
# Initial states:
#   l[0]      b[0]
# 1530.841 0.9328007
# sigma^2:  1e-04
fit_3_coef <- coef(fit_3) |>
select(term, estimate)
# fit_3_coef[1,2] # alpha
# fit_3_coef[2,2] # beta
# fit_3_coef[3,2] # l[0]
# fit_3_coef[4,2] # b[0]
# Residuals from 1 to R
resid_3 <- residuals(fit_3) |>
as_tibble() |> select(.resid)
level <- numeric(T+1) |> as.numeric()
level[1] <- fit_3_coef[3,2] # l_0
trend <- numeric(T+1) |> as.numeric()
trend[1] <- fit_3_coef[4,2] # b_0
# level[2] <- (level[1] + trend[1])*(1 + fit_3_coef[1,2]*resid_3[1,1]) # l_1
# level[3] <- (level[2] + trend[2])*(1 + fit_3_coef[1,2]*resid_3[2,1]) # l_2
#
# trend[2] <- trend[1] + fit_3_coef[1,2]*fit_3_coef[2,2]*(level[1] + trend[1])*resid_3[1,1] # b_1
# trend[3] <- trend[2] + fit_3_coef[1,2]*fit_3_coef[2,2]*(level[2] + trend[2])*resid_3[2,1] # b_2
# Level and Trend from initial value (0) to R (R+1 in total)
for (j in 1:R) {
level[j+1] <- (level[[j]] + trend[[j]])*(1 + fit_3_coef[1,2]*resid_3[j,1])
trend[j+1] <- trend[[j]] + fit_3_coef[1,2]*fit_3_coef[2,2]*(level[[j]] + trend[[j]])*resid_3[j,1]
}
# Residuals from t+1 to T
resid_3_new <- numeric(P) |> as.numeric()
for(i in 1:P) {
resid_3_new[i] <- (test[i,2] - (level[[R+i]] + trend[[R+i]])) / ((level[[R+i]] + trend[[R+i]]))
level[R+i+1] <- (level[[R+i]] + trend[[R+i]])*(1 + fit_3_coef[1,2]*resid_3_new[i])
trend[R+i+1] <- trend[[R+i]] + fit_3_coef[1,2]*fit_3_coef[2,2]*(level[[R+i]] + trend[[R+i]])*resid_3_new[i]
}
# Conditional Mean for SP500
mean_3 <- numeric(P) |> as.numeric()
for (j in 1:P) {
mean_3[j] <- level[[R+j]] + trend[[R+j]]
}
mean_3 <- as_tibble(mean_3)
# Conditional Variance for SP500
# The full prediction density can be estimated using a kernel density estimator (Silverman 1986) applied to yn+h|n.
# The forecast variance is given by
var_3 <- glance(fit_3) |> select(sigma2) |> as.numeric()
var_3 <- mean_3^2*var_3
sd_3 <- sqrt(var_3)
# Predictive Density
pd_3 <- numeric(P) |> as.numeric()
for (j in 1:P) {
pd_3[j] <- dnorm(test[[j,2]], mean_3[[j,1]], sd_3[[j,1]])
}
LS_3 <- sum(log(pd_3)) / P
LS_3
# -5.835116
# Model: LM w/ ARIMA(1,0,0) errors
fit_4 <- train |> model(ARIMA(SP500 ~ trend()))
report(fit_4)
# fit_4 <- train |> model(ARIMA(log(SP500) ~ trend()))
# fit_4 |> gg_tsresiduals()
# Coefficients:
#          ar1  trend()  intercept
#       0.9859   0.7904  1576.9529
# s.e.  0.0041   0.0664    59.3815
# sigma^2 estimated as 328.5
# The model can be rewritten as
# y_t = (\beta_0 - \phi_1\beta_0 + \phi_1\beta_1)+ \phi_1 y_{t-1} + (\beta_1 - \phi_1\beta_1) t + u_t
fit_4_coef <- coef(fit_4) |>
select(term, estimate)
# fit_4_coef[1,2] # ar1
# fit_4_coef[2,2] # trend
# fit_4_coef[3,2] # constant
# # Residual vector for time from t to T (P+1)
# # Observed value - Fitted value
# resid_4 <- numeric(P) |> as.numeric()
# # u_2 (t=2) = train[2,2] - (fit_4_coef[3,2] - fit_4_coef[1,2]*fit_4_coef[3,2] + fit_4_coef[1,2]*fit_4_coef[2,2] + fit_4_coef[1,2]*train[1,2] + (fit_4_coef[2,2] - fit_4_coef[1,2]*fit_4_coef[2,2])*2)
# # u_t (t=R) = train[R,2] - (fit_4_coef[3,2] - fit_4_coef[1,2]*fit_4_coef[3,2] + fit_4_coef[1,2]*fit_4_coef[2,2] + fit_4_coef[1,2]*train[R-1,2] + (fit_4_coef[2,2] - fit_4_coef[1,2]*fit_4_coef[2,2])*R)
# # u_t+1 = y_t+1 - yhat_t+1
# # yhat_t+1 = (constant - ar_1*constant + ar_1*trend)+ ar_1* y_{t-1} + (trend - ar_1*trend) t
# resid_4[1] <- test[1,2] - (fit_4_coef[3,2] - fit_4_coef[1,2]*fit_4_coef[3,2] + fit_4_coef[1,2]*fit_4_coef[2,2] + fit_4_coef[1,2]*train[R,2] + (fit_4_coef[2,2] - fit_4_coef[1,2]*fit_4_coef[2,2])*(R+1))
# for (j in 2:P) {
#   resid_4[j] <- test[j,2] - (fit_4_coef[3,2] - fit_4_coef[1,2]*fit_4_coef[3,2] + fit_4_coef[1,2]*fit_4_coef[2,2] + fit_4_coef[1,2]*test[j-1,2] + (fit_4_coef[2,2] - fit_4_coef[1,2]*fit_4_coef[2,2])*(R+j))
# }
# Conditional Mean for log(SP500) from R+1 to T (P in total)
mean_4 <- numeric(P) |> as.numeric()
# E(y_t+1|t) = (\beta_0 - \phi_1\beta_0 + \phi_1\beta_1)+ \phi_1 y_{t} + (\beta_1 - \phi_1\beta_1)*(t+1)
# Conditional mean for R+1
mean_4[1] <- (fit_4_coef[3,2] - fit_4_coef[1,2]*fit_4_coef[3,2] + fit_4_coef[1,2]*fit_4_coef[2,2] + fit_4_coef[1,2]*train[R,2] + (fit_4_coef[2,2] - fit_4_coef[1,2]*fit_4_coef[2,2])*(R+1))
# Conditional mean for R+2 to T
for (j in 2:P) {
mean_4[j] <- (fit_4_coef[3,2] - fit_4_coef[1,2]*fit_4_coef[3,2] + fit_4_coef[1,2]*fit_4_coef[2,2] + fit_4_coef[1,2]*test[j-1,2] + (fit_4_coef[2,2] - fit_4_coef[1,2]*fit_4_coef[2,2])*(R+j))
}
# (Conditional) Variance for SP500
var_4 <- glance(fit_4) |> select(sigma2)
sd_4 <- sqrt(var_4) |> as.numeric()
# Predictive Density
pd_4 <- numeric(P) |> as.numeric()
for (j in 1:P) {
pd_4[j] <- dnorm(test[[j,2]], mean_4[[j]], sd_4[[1]])
}
LS_4 <- sum(log(pd_4)) / P
LS_4
# -7.472367
# Model: LM w/ ARIMA(1,0,0) errors
fit_5 <- train |> model(ARIMA(log(SP500) ~ trend()))
report(fit_5)
# Coefficients:
#          ar1  trend()  intercept
#       0.9855    4e-04     7.3957
# s.e.  0.0043    0e+00     0.0262
# sigma^2 estimated as 6.706e-05
fit_5_coef <- coef(fit_5) |>
select(term, estimate)
# fit_5_coef[1,2] # ar1
# fit_5_coef[2,2] # trend
# fit_5_coef[3,2] # constant
# Conditional Mean for log(SP500) from R+1 to T (P in total)
mean_5 <- numeric(P) |> as.numeric()
# Conditional mean for R+1 to T
mean_5[1] <- (fit_5_coef[3,2] - fit_5_coef[1,2]*fit_5_coef[3,2] + fit_5_coef[1,2]*fit_5_coef[2,2] + fit_5_coef[1,2]*train[R,4] + (fit_5_coef[2,2] - fit_5_coef[1,2]*fit_5_coef[2,2])*(R+1))
for (j in 2:P) {
mean_5[j] <- (fit_5_coef[3,2] - fit_5_coef[1,2]*fit_5_coef[3,2] + fit_5_coef[1,2]*fit_5_coef[2,2] + fit_5_coef[1,2]*test[j-1,4] + (fit_5_coef[2,2] - fit_5_coef[1,2]*fit_5_coef[2,2])*(R+j))
}
# (Conditional) Variance for SP500
var_5 <- glance(fit_5) |> select(sigma2)
sd_5 <- sqrt(var_5) |> as.numeric()
# Predictive Density
pd_5 <- numeric(P) |> as.numeric()
for (j in 1:P) {
pd_5[j] <- dlnorm(test[[j,2]], mean_5[[j]], sd_5[[1]])
}
LS_5 <- sum(log(pd_5)) / P
LS_5
# -5.871551
# Find the optimal weight by optimazing the log predictive score
w <- seq(from = 0, to = 1, by = 0.01)
pool <- numeric(length(w)) |> as.numeric()
# ARIMA(1,1,1) w/ drift and ETS(M,N,N)
# weight on the first model
for (j in 1:length(w)) {
pool[j] <-  sum(log(w[j]*pd_1b + (1-w[j])*pd_2))/P
}
comb <- cbind(w,pool) |> as_tibble()
comb |> filter(pool == max(comb$pool))
# w = 0.45
# pool = -5.79
comb |> ggplot(aes(w, pool)) +
geom_line(color = "red") +
labs(title = "ARIMA(1,1,1) w/ drift, ETS(M,N,N)",
x = "Weight on model ARIMA",
y = "Log predictive socre") +
theme(plot.title = element_text(hjust = 0.5))
# ARIMA(1,1,1) w/ drift and ETS(M,A,N)
# weight on the first model
for (j in 1:length(w)) {
pool[j] <-  sum(log(w[j]*pd_1b + (1-w[j])*pd_3))/P
}
comb <- cbind(w,pool) |> as_tibble()
comb |> filter(pool == max(comb$pool))
# w = 0.43
# pool = -5.80
comb |> ggplot(aes(w, pool)) +
geom_line(color = "red") +
labs(title = "ARIMA(1,1,1) w/ drift, ETS(M,A,N)",
x = "Weight on model ARIMA",
y = "Log predictive socre") +
theme(plot.title = element_text(hjust = 0.5))
# ETS(M,N,N) and ETS(M,A,N)
# weight on the first model
for (j in 1:length(w)) {
pool[j] <-  sum(log(w[j]*pd_2 + (1-w[j])*pd_3))/P
}
comb <- cbind(w,pool) |> as_tibble()
comb |> filter(pool == max(comb$pool))
# w = 0.08
# pool = -5.84
comb |> ggplot(aes(w, pool)) +
geom_line(color = "red") +
labs(title = "ETS(M,N,N), ETS(M,A,N)",
x = "Weight on model ETS(M,N,N)",
y = "Log predictive socre") +
theme(plot.title = element_text(hjust = 0.5))
# ARIMA(1,1,1) w/ drift and LM
# weight on the first model
for (j in 1:length(w)) {
pool[j] <-  sum(log(w[j]*pd_1b + (1-w[j])*pd_5))/P
}
comb <- cbind(w,pool) |> as_tibble()
comb |> filter(pool == max(comb$pool))
# w = 0.49
# pool = -2.95
comb |> ggplot(aes(w, pool)) +
geom_line(color = "red") +
labs(title = "ARIMA(1,1,1) w/ drift, LM",
x = "Weight on model ARIMA",
y = "Log predictive socre") +
theme(plot.title = element_text(hjust = 0.5))
# ETS(M,N,N) and LM
# weight on the first model
for (j in 1:length(w)) {
pool[j] <-  sum(log(w[j]*pd_2 + (1-w[j])*pd_5))/P
}
comb <- cbind(w,pool) |> as_tibble()
comb |> filter(pool == max(comb$pool))
# w = 0.49
# pool = -2.92
comb |> ggplot(aes(w, pool)) +
geom_line(color = "red") +
labs(title = "ETS(M,N,N), LM",
x = "Weight on model ETS(M,N,N)",
y = "Log predictive socre") +
theme(plot.title = element_text(hjust = 0.5))
# ETS(M,A,N) and LM
# weight on the first model
for (j in 1:length(w)) {
pool[j] <-  sum(log(w[j]*pd_3 + (1-w[j])*pd_5))/P
}
comb <- cbind(w,pool) |> as_tibble()
comb |> filter(pool == max(comb$pool))
# w = 0.49
# pool = -2.92
comb |> ggplot(aes(w, pool)) +
geom_line(color = "red") +
labs(title = "ETS(M,A,N), LM",
x = "Weight on model ETS(M,A,N)",
y = "Log predictive socre") +
theme(plot.title = element_text(hjust = 0.5))
return <- train |> model(ARIMA(return^2))
report(fit_5)
library(readxl)
library(fpp3)
library(tidyverse)
library(dplyr)
# https://www.abs.gov.au/statistics/industry/retail-and-wholesale-trade/retail-trade-australia/latest-release#data-downloads
# food <- read.csv("Food retailing.csv")
food <- read_xlsx("850101.xlsx", range = "Data1!A11:B500", col_names = c("Month", "Turnover"))
food <- food |>
mutate(Month = yearmonth(Month)) |>
as_tsibble(index = "Month")
food <- food |> mutate(Log = log(Turnover))
T <- nrow(food)
# In-sample - Training Set
train <- food[1:floor(nrow(food)*.75),] |> as_tsibble()
R <- nrow(train)
# Out-of-sample - Test set
test <- food[(R+1):nrow(food),] |> as_tsibble()
P <- nrow(test)
m <- 12
# Preliminary Analysis
# train |> autoplot(Turnover)
# train |> autoplot(log(Turnover))
# train |> features(Turnover, features = guerrero)
# train |> gg_season(Turnover)
# train |> gg_subseries(Turnover)
# train |> autoplot(difference(log(Turnover),12))
# train |> gg_tsdisplay(difference(log(Turnover),12), "partial")
# train |> gg_tsdisplay(difference(difference(log(Turnover),12),1), "partial")
# Model: ETS(M,A,M)
fit_1 <- train |>
model(ETS(Turnover))
report(fit_1)
# Smoothing parameters:
#   alpha = 0.2379844
#   beta  = 0.01125871
#   gamma = 0.0001107135
# Initial states:
#     l[0]    b[0]     s[0]     s[-1]    s[-2]    s[-3]    s[-4]    s[-5]
# 1169.327 9.67961 1.012064 0.9370364 1.003077 1.161438 1.011628 1.015776
#     s[-6]     s[-7]     s[-8]     s[-9]    s[-10]    s[-11]
# 0.9706842 0.9924231 0.9833296 0.9509841 0.9853554 0.9762041
# sigma^2:  4e-04
# train |>
#   model(STL(log(Turnover) ~ trend(window = 7) + season(window = "periodic"),
#             robust = TRUE)) |>
#   components() |> autoplot()
# Model: ETS(M,Ad,M)
# fit_4 <- train |>
#   model(ETS(Turnover ~ error("M") + trend("Ad") + season("M")))
# report(fit_4)
# Smoothing parameters:
#   alpha = 0.1501255
#   beta  = 0.08061994
#   gamma = 0.0001026361
#   phi   = 0.9636318
# Initial states:
#    l[0]     b[0]     s[0]     s[-1]    s[-2]    s[-3]    s[-4]    s[-5]
# 1168.37 14.13597 1.012941 0.9373244 1.003313 1.162376 1.010097 1.015824
#    s[-6]     s[-7]     s[-8]    s[-9]    s[-10]    s[-11]
# 0.969727 0.9924589 0.9821148 0.950848 0.9865899 0.9763853
# sigma^2:  4e-04
fit_1_coef <- coef(fit_1) |>
select(term, estimate)
# fit_1_coef[1,2] # alpha
# fit_1_coef[2,2] # beta
# fit_1_coef[3,2] # gamma
# fit_1_coef[4,2] # l[0]
# fit_1_coef[5,2] # b[0]
# fit_1_coef[6,2] # s[0]
# fit_1_coef[7,2] # s[-1]
# ...
# fit_1_coef[17,2] # s[-11]
# Residuals from 1 to R
resid_1 <- residuals(fit_1) |>
as_tibble() |>
select(.resid)
level <- numeric(T+1) |> as.numeric()
level[1] <- fit_1_coef[4,2] # l_0
trend <- numeric(T+1) |> as.numeric()
trend[1] <- fit_1_coef[5,2] # b_0
season <- numeric(T+12) |> as.numeric()
for (j in 1:12) {
season[j] <- fit_1_coef[18-j,2]
}
# Level and Trend from initial value (0) to R (R+1 in total)
for (j in 1:R) {
level[j+1] <- (level[[j]] + trend[[j]]) * (1 + fit_1_coef[1,2]*resid_1[j,1])
trend[j+1] <- trend[[j]] + (fit_1_coef[1,2]*fit_1_coef[2,2])*(level[[j]] + trend[[j]])*resid_1[j,1]
}
# Season from t=1 to R
for (j in 1:R) {
season[j+m] <- season[[j]]*(1 + fit_1_coef[3,2]*resid_1[j,1])
}
# Residuals from t+1 to P
resid_1_new <- numeric(P) |> as.numeric()
# resid_1_new[1] <- test[1,2] - (level[[R+1]] + trend[[R+1]])*season[[R+1]]
# (level[[R+1]] + trend[[R+1]])*(1 + fit_1_coef[1,2]*resid_1_new[[1]])
# trend[[R+1]] + fit_1_coef[1,2]*fit_1_coef[2,2]*(level[[R+1]] + trend[[R+1]])*resid_1_new[[1]]
# season[[R+1]]*(1 + fit_1_coef[3,2]*resid_1_new[[1]])
# resid[R+1] = y_R+1 - (l_R + b_R)*s_R+1-m  season[R+1]-S(R+1-m)
# resid[R+2] = y_R+2 - (l_R+1 + b_R+1)*s_R+2-m  season[R+2]-S(R+2-m)
for(i in 1:P) {
resid_1_new[i] <- (test[i,2] - (level[[R+i]] + trend[[R+i]])*season[[R+i]]) / ((level[[R+i]] + trend[[R+i]])*season[[R+i]])
level[R+i+1] <- (level[[R+i]] + trend[[R+i]])*(1 + fit_1_coef[1,2]*resid_1_new[[i]])
trend[R+i+1] <- trend[[R+i]] + fit_1_coef[1,2]*fit_1_coef[2,2]*(level[[R+i]] + trend[[R+i]])*resid_1_new[[i]]
season[R+m+i] <- season[[R+i]]*(1 + fit_1_coef[3,2]*resid_1_new[[i]])
}
# season[13]-S1  season[14]-S2   season[R+1+m]-S(R+1)
# Conditional Mean for SP500
mean_1 <- numeric(P) |> as.numeric()
for (j in 1:P) {
mean_1[j] <- (level[[R+j-1]] + trend[[R+j-1]])*season[[R+j]]
}
# Conditional Variance for SP500
var <- glance(fit_1) |> select(sigma2) |> as.numeric()
var_1 <- numeric(P) |> as.numeric()
for (j in 1:P) {
var_1[j] <- mean_1[j]^2*var
}
sd_1 <- as.numeric(var_1) |> sqrt()
pd_1 <- numeric(P) |> as.numeric()
for (j in 1:P) {
pd_1[j] <- dnorm(test[[j,2]], mean_1[j], sd_1[j])
}
LS_1 <- sum(log(pd_1)) / P
LS_1
#-14.27422
# Model: ARIMA(0,1,2)(0,1,0)[12]
fit_2 <- train |>
model(ARIMA(log(Turnover) ~ pdq(0,1,2) + PDQ(0,1,0)))
report(fit_2)
# gg_tsresiduals(fit_2)
# Coefficients:
#           ma1     ma2
#       -0.9942  0.3695
# s.e.   0.0489  0.0436
# sigma^2 estimated as 0.0005144
fit_2_coef <- coef(fit_2) |>
select(term, estimate)
# fit_2_coef[1,2] ma1
# fit_2_coef[2,2] ma2
resid_2 <- numeric(P+2) |> as.numeric()
resid_2[1] <- residuals(fit_2) |>
as_tibble() |>
select(.resid) |>
slice(R-1) # epsilon_t-1
resid_2[2] <- residuals(fit_2) |>
as_tibble() |>
select(.resid) |>
slice(R) # epsilon_t
(train[,3]-log(fitted(fit_2)$.fitted)) == residuals(fit_2)$.resid
# Residual vector for time from t+1 to T (P)
# Observed value - Fitted value
# yhat_t = y_t-1 + y_t-12 - y_t-13 + ma1*resid_t-1 + ma2*resid_t-2
# e_t+1
resid_2[3] <- test[1,3] - (train[R,3] + train[R-11,3] - train[R-12,3] + fit_2_coef[1,2]*resid_2[2] + fit_2_coef[2,2]*resid_2[1])
# e_t+2 to e_t+12
for(j in 1:11){
resid_2[j+3] <- test[j+1,3] - (test[j,3] + train[R-11+j,3] - train[R-12+j,3] + fit_2_coef[1,2]*resid_2[j+2] + fit_2_coef[2,2]*resid_2[j+1])
}
# e_t+13
resid_2[15] <- test[13,3] - (test[12,3] + test[1,3] - train[R,3] + fit_2_coef[1,2]*resid_2[14] + fit_2_coef[2,2]*resid_2[13])
# e_t+14
resid_2[16] <- test[14,3] - (test[13,3] + test[2,3] - test[1,3] + fit_2_coef[1,2]*resid_2[15] + fit_2_coef[2,2]*resid_2[14])
# e_t+15 to e_t+P
for(j in 17:(P+2)){
resid_2[j] <- test[j-2,3] - (test[j-3,3] + test[j-14,3] - test[j-15,3] + fit_2_coef[1,2]*resid_2[j-1] + fit_2_coef[2,2]*resid_2[j-2])
}
# Conditional Mean for turnover
mean_2 <- numeric(P) |> as.numeric()
# E(y_t+1) = y_t + y_t-11 + y_t-12 + ma1*resid_t + ma2*resid_t-1
mean_2[1] <- train[R,3] + train[R-11,3] - train[R-12,3] + fit_2_coef[1,2]*resid_2[2] + fit_2_coef[2,2]*resid_2[1]
# E(y_t+2) = y_t+1 + y_t-10 + y_t-11 + ma1*resid_t+1 + ma2*resid_t
for (j in 2:12) {
mean_2[j] <- test[j-1,3] + train[R-12+j,3] - train[R-13+j,3] + fit_2_coef[1,2]*resid_2[j+1] + fit_2_coef[2,2]*resid_2[j]
}
# E(y_t+13) = y_t+12 + y_t+1 + y_t + ma1*resid_t+12 + ma2*resid_t+11
mean_2[13] <- test[12,3] + test[1,3] - train[R,3] + fit_2_coef[1,2]*resid_2[14] + fit_2_coef[2,2]*resid_2[13]
# E(y_t+14) = y_t+13 + y_t+2 + y_t+1 + ma1*resid_t+13 + ma2*resid_t+12
for (j in 14:P) {
mean_2[j] <- test[j-1,3] + test[j-12,3] - test[j-13,3] + fit_2_coef[1,2]*resid_2[j+1] + fit_2_coef[2,2]*resid_2[j]
}
# Conditional Variance for SP500
var_2 <- glance(fit_2) |> select(sigma2) |> as.numeric()
sd_2 <- sqrt(var_2)
pd_2 <- numeric(P) |> as.numeric()
for (j in 1:P) {
pd_2[j] <- dnorm(test[[j,3]], mean_2[[j]], sd_2[[1]])
}
LS_2 <- sum(log(pd_2)) / P
LS_2
#1.775308
# If the log of a variable follows a normal distribution, then the variable itself follows a log-normal distribution.
# A log-normal distribution is a probability distribution of a random variable whose logarithm follows a normal distribution.
# Mathematically, the log-normal probability density function (pdf) can be expressed as:
#   f(x) = 1 / (x * σ * sqrt(2π)) * exp(-((ln(x) - μ)^2) / (2 * σ^2))
# where μ and σ are the mean and standard deviation of the logarithm of X, respectively.
pd_2b <- numeric(P) |> as.numeric()
for (j in 1:P) {
pd_2b[j] <- dlnorm(test[[j,2]], mean_2[[j]], sd_2[[1]])
}
LS_2b <- sum(log(pd_2b)) / P
LS_2b
# -7.52116
# Find the optimal weight by optimazing the log predictive score
w <- seq(from = 0, to = 1, by = 0.01)
pool <- numeric(length(w)) |> as.numeric()
# ETS(M,A,M) and ARIMA(0,1,2)(0,1,0)[12]
# weight on the first model
for (j in 1:length(w)) {
pool[j] <-  sum(log(w[j]*pd_1 + (1-w[j])*pd_2b))/P
}
comb <- cbind(w,pool) |> as_tibble()
comb |> filter(pool == max(comb$pool))
# w = 0.35
# pool = -7.10
comb |> ggplot(aes(w, pool)) +
geom_line(color = "red") +
labs(title = "ETS(M,A,M) , ARIMA(0,1,2)(0,1,0)[12] ",
x = "Weight on model ETS",
y = "Log predictive socre") +
theme(plot.title = element_text(hjust = 0.5))
install.packages(c("blob", "car", "cli", "commonmark", "dbplyr", "distributional", "dplyr", "dtplyr", "fable", "fabletools", "feasts", "ggplot2", "googledrive", "googlesheets4", "greybox", "gt", "gtable", "hms", "htmltools", "htmlwidgets", "lattice", "lme4", "markdown", "Matrix", "modelr", "parallelly", "pillar", "ps", "quantmod", "RcppArmadillo", "rlang", "rmarkdown", "survival", "testthat", "tibble", "vctrs", "xfun"))
install.packages(c("blob", "car", "cli", "commonmark", "dbplyr", "distributional", "dplyr", "dtplyr", "fable", "fabletools", "feasts", "ggplot2", "googledrive", "googlesheets4", "greybox", "gt", "gtable", "hms", "htmltools", "htmlwidgets", "lattice", "lme4", "markdown", "Matrix", "modelr", "parallelly", "pillar", "ps", "quantmod", "RcppArmadillo", "rlang", "rmarkdown", "survival", "testthat", "tibble", "vctrs", "xfun"))
install.packages(c("blob", "car", "cli", "commonmark", "dbplyr", "distributional", "dplyr", "dtplyr", "fable", "fabletools", "feasts", "ggplot2", "googledrive", "googlesheets4", "greybox", "gt", "gtable", "hms", "htmltools", "htmlwidgets", "lattice", "lme4", "markdown", "Matrix", "modelr", "parallelly", "pillar", "ps", "quantmod", "RcppArmadillo", "rlang", "rmarkdown", "survival", "testthat", "tibble", "vctrs", "xfun"))
install.packages(c("blob", "car", "cli", "commonmark", "dbplyr", "distributional", "dplyr", "dtplyr", "fable", "fabletools", "feasts", "ggplot2", "googledrive", "googlesheets4", "greybox", "gt", "gtable", "hms", "htmltools", "htmlwidgets", "lattice", "lme4", "markdown", "Matrix", "modelr", "parallelly", "pillar", "ps", "quantmod", "RcppArmadillo", "rlang", "rmarkdown", "survival", "testthat", "tibble", "vctrs", "xfun"))
future <- new_data(sales, n=4) %>%
mutate(AdBudget = tail(sales$AdBudget, 1),
GDP = tail(sales$GDP, 1)
)
sales %>%
pivot_longer(Sales:GDP) %>%
autoplot(value) +
facet_grid(name ~ ., scales = "free_y") +
theme(legend.position = "none")
?biblatex
??biblatex
install.packages("biblatex")
library(monash)
remove.packages("monash")
install.packages("monash")
install.packages("monash")
install.packages(monash)
install.packages("monash")
install.packages("monash")
install.packages("monash")
