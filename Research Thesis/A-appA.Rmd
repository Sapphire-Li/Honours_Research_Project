---
knit: "bookdown::render_book"
---

\appendix

# Appendix  

```{r, echo=FALSE, eval=FALSE}
citation("tidyverse")
citation("dplyr")
citation("fpp3")
citation("mvtnorm")
citation("gridExtra")
version$version.string
```

All codes are performed in R Statistical Software (version 4.2.1 (2022-06-23)). The packages used are `tidyverse` [@tidy19], `dplyr` [@dplyr23], `fpp3` [@fpp23], `gridExtra` [@gridExtra], and `mvtnorm` [@GBMMLSH21].


## Model Specification

The error term, $\epsilon_t$, in each model is assumed to be independent and normally distributed with a zero mean and a constant variance. Each model is independent. Even if using the same notation for unknown parameters across models, the estimators are different.

Exact formulas and explanations of these models can be found in @fpp3. The formula of the conditional variance for the ETS(M,N,N) model is discussed in Chapter 6.3 of @HKOS08.

### Nonstationary S\&P 500 Index

1. ARIMA(1,1,1) model with an intercept of the natural logarithm of S\&P 500 index. 
\begin{equation*}
log(y_t) = c + log(y_{t-1}) + \phi_1\big[log(y_{t-1})-log(y_{t-2})\big] + \epsilon_t + \theta_1\epsilon_{t-1}
\end{equation*}

2. ETS(M,N,N) model of the natural logarithm of S\&P 500 index. 
\begin{align*}
log(y_t) &= \ell_{t-1} (1+\epsilon_t) \\
\ell_t &= \ell_{t-1} (1+\alpha \epsilon_t) \\
\end{align*}

3. A classical linear regression model of the natural logarithm of the S\&P 500 index and ARIMA(1,0,0) errors. 
\begin{align*}
log(y_t) &= \beta_0 + \beta_1 t + u_t \\
u_t &= \phi_1 u_{t-1} + \epsilon_t
\end{align*}



### Stationary S\&P 500 Index

1. ARMA(1,1) model with an intercept of the natural logarithm of S\&P 500 returns. 
\begin{equation*}
log(y_t) - log(y_{t-1}) = c + \phi_1\big[log(y_{t-1})-log(y_{t-2})\big] + \epsilon_t + \theta_1\epsilon_{t-1}
\end{equation*}

2. A classical linear regression model of the natural logarithm of the S\&P 500 returns and ARMA(1,1) errors. 
\begin{align*}
log(y_t) - log(y_{t-1}) &= \beta_0 + u_t \\
u_t &= \phi_1 u_{t-1} + \epsilon_t + \theta_1\epsilon_{t-1}
\end{align*}



### Well-specified Models for Seasonal Unemployment Dataset

1. ARIMA(2,0,2)(0,1,1)[4] model with an intercept of the natural logarithm of unemployed individuals.
\begin{align*}
log(y_t) &= c + log(y_{t-4}) + \phi_1\big[log(y_{t-1})-log(y_{t-5})\big] + \phi_2\big[log(y_{t-2})-log(y_{t-6})\big] \\
         &+ \epsilon_t + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \Theta_1\epsilon_{t-4} + \theta_1\Theta_1\epsilon_{t-5} + \theta_2\Theta_1\epsilon_{t-6} \\
\end{align*}


2. ETS(A,A,A) model of the natural logarithm of unemployed individuals. 
\begin{align*}
log(y_t) &= \ell_{t-1} + b_{t-1} + s_{t-m} + \epsilon_t \\
\ell_t &= \ell_{t-1} + b_{t-1} + \alpha \epsilon_t \\
b_t &= b_{t-1} + \beta \epsilon_t \\
s_{t} &= s_{t-m} + \gamma \epsilon_t
\end{align*}



### Poorly-specified Models for Seasonal Unemployment Dataset

1. ARIMA(2,1,0) model with an intercept of the natural logarithm of unemployed individuals.
\begin{equation*}
log(y_t) = c + log(y_{t-1}) + \phi_1\big[log(y_{t-1})-log(y_{t-2})\big] + \phi_2\big[log(y_{t-2})-log(y_{t-3})\big] + \epsilon_t
\end{equation*}

2. ETS(A,A,N) model of the natural logarithm of unemployed individuals. 
\begin{align*}
log(y_t) &= \ell_{t-1} + b_{t-1} + \epsilon_t \\
\ell_t &= \ell_{t-1} + b_{t-1} + \alpha \epsilon_t \\
b_t &= b_{t-1} + \beta \epsilon_t
\end{align*}





## Optimal Weight Derivation Details {#detail}

In this section, we detail the derivation steps of producing the results in Section \@ref(op).

Recall that the data is drawn from the true DGP:
\[y_i = \beta_1 x_{1i} + \beta_2 x_{2i} + \epsilon_i, \ \ \epsilon_i \stackrel{i.i.d}{\sim} N(0,\sigma^2_{\epsilon}) \]
where the in-sample period (R) is used to estimate the parameters for the following two constituent models:
\begin{align*}
M_1: y_i &= \alpha_1 x_{1i} + u_{1i}, \ \ u_{1i} \stackrel{i.i.d}{\sim} N(0,\sigma^2_1) \\
M_2: y_i &= \alpha_2 x_{2i} + u_{2i}, \ \ u_{2i} \stackrel{i.i.d}{\sim} N(0,\sigma^2_2).
\end{align*}

Besides, we allow $x_{1i}$ and $x_{2i}$ to have a small correlation, otherwise, there may be multicollinearity, resulting in higher standard errors of estimated parameters.

For simplicity, these models can be written in matrix forms
\begin{align*}
y &= x_1 \beta_{1} + x_2 \beta_{2} + \epsilon \\
M_1 : y &= x_1 \alpha_{1} + u_1 \\
M_2 : y &= x_2 \alpha_{2} + u_2
\end{align*}
where
\[
     {y}=\begin{bmatrix}
           y_{1} \\
           y_{2} \\
           \vdots \\
           y_{N}
         \end{bmatrix},\;
     {x_1}=\begin{bmatrix}
           x_{11} \\
           x_{21} \\
           \vdots \\
           x_{N1}
         \end{bmatrix},\;
    {x_2}=\begin{bmatrix}
           x_{12} \\
           x_{22} \\
           \vdots \\
           x_{N2}
         \end{bmatrix},\;
    {\epsilon}=\begin{bmatrix}
           \epsilon_{1} \\
           \epsilon_{2} \\
           \vdots \\
           \epsilon_{N}
         \end{bmatrix}.
\]

Applying the OLS estimation, we can immediately obtain the formula of $\hat\alpha_{1}$ and $\hat\alpha_{2}$. Given a weak correlation between regressors, each formula will have an extra component, which represents that correlation.
\begin{align*}
    \hat\alpha_{1} &= (x'_1x_1)^{-1} x'_1y \\
    &= (x'_1x_1)^{-1} x'_1(x_1 \beta_1 + x_2 \beta_2 + \epsilon) \\
    &= \beta_1 + (x'_1x_1)^{-1} x'_1x_2 \beta_2 \\
    &= \beta_1 + var(x_1)^{-1} cov(x_1,x_2) \beta_2 \\
    \\
    \hat\alpha_{2} &= (x'_2x_2)^{-1} x'_2y \\
    &= (x'_2x_2)^{-1} x'_2(x_1 \beta_1 + x_2 \beta_2 + \epsilon) \\
    &= \beta_2 + (x'_2x_2)^{-1} x'_2x_1 \beta_1 \\
    &= \beta_2 + var(x_2)^{-1} cov(x_2,x_1) \beta_1 \\
\end{align*}
\begin{align*}
    \hat y_{\omega} &= \hat y_1 \omega + \hat y_2 (1-\omega) \\
    &= x_1 \hat\alpha_1 \omega + \ x_2 \hat\alpha_2 (1-\omega) \\
    &= x_1 \hat\alpha_1 \omega - x_2 \hat\alpha_2 \omega + x_2 \hat\alpha_2 \\
    &= (x_1 \hat\alpha_1 - x_2 \hat\alpha_2) \omega + x_2 \hat\alpha_2 
\end{align*}

\begin{align*}
\hat{\omega}_{\text{opt}} 
&= \underset{\omega \in [0,1]}{\arg\min} \ \frac{1}{R} \sum^R_{t=1} \big(y - \hat y_{\omega}\big)' \big(y - \hat y_{\omega}\big) \\
&= \underset{\omega \in [0,1]}{\arg\min} \ \frac{1}{R} \sum^R_{t=1} \big[y-(x_1 \hat\alpha_1 - x_2 \hat\alpha_2) \omega - x_2 \hat\alpha_2\big]'\big[y-(x_1 \hat\alpha_1 - x_2 \hat\alpha_2) \omega - x_2 \hat\alpha_2\big]\\
\end{align*}
\begin{align*}
    -2(x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' (y-(x_1 \hat\alpha_1 - x_2 \hat\alpha_2) \hat\omega_{opt} - x_2 \hat\alpha_2) &= 0 \\
    (x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' (x_1 \hat\alpha_1 - x_2 \hat\alpha_2) \hat\omega_{opt} &= (x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' (y - x_2 \hat\alpha_2) \\
    \hat\omega_{opt} &= \frac{(x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' (y - x_2 \hat\alpha_2)}{(x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' (x_1 \hat\alpha_1 - x_2 \hat\alpha_2)} \\
    \hat\omega_{opt} &= \frac{(x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' (y - x_2 \hat\alpha_2)}{(x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' (x_1 \hat\alpha_1 - x_2 \hat\alpha_2)} \\
    \hat\omega_{opt} &= \frac{(x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' y - (x_1 \hat\alpha_1 - x_2 \hat\alpha_2)' x_2 \hat\alpha_2}{\hat\alpha'_1 x'_1 x_1 \hat\alpha_1 - 2\hat\alpha'_1 x'_1 x_2 \hat\alpha_2 + \hat\alpha'_2 x'_2 x_2 \hat\alpha_2} \\
\end{align*}






### Formula related to the $F$-statistics

To clearly see the relationship between the in-sample fit and the optimal weight, equation \ref{eqn:opt} can be linked with the F-statistics of two models. The F-test of overall significance is a formal hypothesis test, which examines the explanatory power of the whole model.


The hypothesis of the overall significance test for $M_1$ can be written as $H_0: R\alpha_1 = r$ and $H_1: R\alpha_1 \ne r$ where $R$ is a scalar 1 (or an identity matrix when $\alpha$ is a column vector) and $r$ is a scalar 0 (or a column vector of 0).

Define $m$ as the number of restrictions in the null hypothesis, and the sum squared of errors (SSE) for the full (true) model \ref{eqn:DGP} is $SSE_{full} = (y - x_1 \hat\beta_1 - x_2 \hat\beta_2)'(y - x_1 \hat\beta_1 - x_2 \hat\beta_2)$. Then the unbiased estimator of the true model variance is $s^2=\frac{SSE_{full}}{R-2}$.

The F-statistic follows a F-distribution with degrees of freedom (1,R-2) under $H_0$, which is defined as
\begin{align*}
F_{\alpha_1} &= (R\hat\alpha_1 - r)'[s^2R(x_1'x_1)^{-1}R']^{-1}(R\hat\alpha_1 - r)/m \\
&= (\hat\alpha_1 - 0)' \Big[s^2(x_1'x_1)^{-1}\Big]^{-1} (\hat\alpha_1 - 0)/1 \\
&= R \ s^{-2} \ \hat\alpha'_1 \text{cov}_R(x_1,x_1) \hat\alpha_1. \\
\end{align*}


Similarly, we have 
\begin{equation*}
F_{\alpha_2} = R \ s^{-2} \ \hat\alpha'_2 \text{cov}_R(x_2,x_2) \hat\alpha_2 \sim F_{1,R-2} \text{ under  H}_0.
\end{equation*}


The optimal weight can also be constructed by the F-statistics of $M_1$ and $M_2$.

\begin{equation*}
\hat\omega_{opt} = \frac{F_{\alpha_1}- R \ \hat\alpha_1'\text{cov}_R(x_1,x_2)\hat\alpha_2/s^2}{F_{\alpha_1} + F_{\alpha_2} - 2 R \ \hat\alpha_1'\text{cov}_R(x_1,x_2)\hat\alpha_2/s^2}.
\end{equation*}

If the covariance between $x_1$ and $x_2$ is close to zero, the optimal weight can be approximated as $\hat\omega_{opt} = \frac{F_{\alpha_1}}{F_{\alpha_1} + F_{\alpha_2}}$. This is the reason why the in-sample performance of model is highly correlated with the presence of the puzzle. 






## Density Simulation 

+ \bf{Sample Size}

It is noticeable that the set of optimal weight varies a lot when we have different sample sizes. Model 1 is given an extremely low weight when $N=50$ whereas it is highly preferred when $N=100$. The optimal weight is 0.48 when the sample size becomes 1000, shown in Figure \ref{fig:ss1000}. Based on the log score curve of in-sample combinations, the optimal weight is highly correlated with the individual model performance. The number of observations can be viewed as one factor that can affect the model fit. Figure \ref{fig:samplesize} also shows that the average density forecast performs much better than the optimal density combination in both cases, i.e., the forecast combination puzzle is found.

\begin{table}[ht]
  \centering
    \begin{tabular}{l|ccc}
    \toprule
    Sample Size      &   $N=50$    &    $N=100$   &  $N=1000$  \\
    \midrule
    $R^2$ of $M_1$   &   0.4928    &    0.4953    &   0.3612   \\
    $R^2$ of $M_2$   &   0.5620    &    0.3320    &   0.3722   \\
    Difference       &   0.0692    &    0.1633    &   0.0110   \\
    Optimal Weight   &    0.07     &     0.98     &    0.48    \\
    Puzzle           &    Yes      &     Yes      &    Yes     \\
    \bottomrule
    \end{tabular}
  \caption{``Difference`` represents the absolute difference of in-sample fit between two models. ``Optimal Weight`` is the estimated weight assigned to $M_1$. ``Puzzle`` indicates whether the simple average is close to or outperforms the optimal forecast combination.}
  \label{tab:size}
\end{table}

Table \ref{tab:size} illustrates that when two models have a relatively big difference in the in-sample fit $R^2$ (in the second and third columns), we are then more likely to have an extreme optimal weight $\omega$. However, when two models have similar $R^2$ in the fourth column, the optimal weight $\omega$ is close to 0.5. These empirical results first support the conjecture that when models have indifferent in-sample fit, the puzzle is likely evidenced. Additionally, they illustrate that the puzzle can be in evidence when one model performs outstandingly.





+ \bf{Magnitude and Sign of $\pmb{\beta}$}

Next, we explore the effect changes in magnitudes or signs of $\beta_1$ and $\beta_2$ given two different sample sizes. From here on, combination plots will be collected and displayed in Appendix \@ref(plot). According to Figure \ref{fig:magnitude}, the puzzle is highly sensitive to the absolute difference between two parameters. If the absolute difference is large enough, generally more than half of the smaller coefficient, it is hard to find the puzzle and the optimal combination always wins with a higher log predictive score. In the linear regression analysis, the magnitude of coefficient represents the impact size of corresponding regressor on the dependent variable. A large value of coefficient means that a change in the regressor will affect the dependent variable more in magnitude. Knowing this, it is reasonable to observe that the Model 1 has a decreasing weight in the optimal combination from left to right in Figure \ref{fig:magnitude}. The effect of $x_{2i}$ on $y_i$, $\beta_2$, is relatively larger than the effect of $x_{1i}$ on $y_i$, $\beta_1$, so the Model 2 with $x_{2i}$ should be weighted higher in the combination.

\begin{table}[ht]
  \centering
    \begin{tabular}{l|cccc}
    \toprule
    Different Magnitudes    &  $\beta_1=2,\ \beta_2=4$   &  $\beta_1=2,\ \beta_2=6$ &  $\beta_1=2,\ \beta_2=4$  &  $\beta_1=2,\ \beta_2=6$  \\
    \midrule
    $R^2$ of $M_1$  &    0.6516    &   0.7057   &    0.4567     &   0.4948   \\
    $R^2$ of $M_2$  &    0.6043    &   0.7574   &    0.6082     &   0.7478   \\
    Difference      &    0.0472    &   0.0517   &    0.1516     &   0.2530   \\
    Optimal Weight  &     0.59     &    0.32    &     0.18      &    0.04    \\
    Puzzle          &     Yes      &     No     &      No       &     No     \\
    Sample Size     &     100      &    100     &     1000      &    1000    \\
    \bottomrule
    \end{tabular}
  \caption{``Difference`` represents the absolute difference of in-sample fit between two models. ``Optimal Weight`` is the estimated weight assigned to $M_1$. ``Puzzle`` indicates whether the simple average is close to or outperforms the optimal forecast combination.}
  \label{tab:bmag}
\end{table}

With reference to the previous results, when the absolute difference is small, the optimal weight $\omega_{opt}$ is expected to be around 0.5 and we are expected to find the puzzle. The second column of Table \ref{tab:bmag} provides another empirical evidence where the absolute difference is around 0.0472. The other three cases, however, illustrate the results when the absolute difference of $R^2$ is big enough. Different from the cases in the second and third columns of Table \ref{tab:size}, the puzzle is not obvious when one model is more favored, and we have the optimal forecast combination outperforms the simple average forecast. Recall our initial conjecture about the combination of a ``Good`` model and a ``Bad`` model, simulations have shown some corroborating evidence that the puzzle is ambiguous.



Table \ref{tab:bsig} further justifies our conjecture of the relationship between the in-sample performance and the presence of the puzzle. Especially when the sample size is 100, there is a huge difference between the in-sample fit of two models and $M_2$ is given all the weight in the optimal combination. This clearly implies that the puzzle is not discovered randomly but related to the model in-sample performance. It is also noticeable that conditioning on the same magnitude, the sample size has a large impact on the model fit. When the sample size is small, the absolute difference of in-sample performance becomes larger, leading to an extreme optimal weight and the presence of the puzzle is uncertain as well.

\begin{table}[ht]
  \centering
    \begin{tabular}{l|cccc}
    \toprule
    Different Signs &  $\beta_1=2,\ \beta_2=-2$  &  $\beta_1=4,\ \beta_2=-4$  &  $\beta_1=2,\ \beta_2=-2$  &  $\beta_1=4,\ \beta_2=-4$\\
    \midrule
    $R^2$ of $M_1$  &    0.0002    &   0.00002  &    0.0131     &   0.0423   \\
    $R^2$ of $M_2$  &    0.1130    &   0.1934   &    0.0321     &   0.0856   \\
    Difference      &    0.1128    &   0.1934   &    0.0191     &   0.0433   \\
    Optimal Weight  &      0       &     0      &     0.38      &    0.38    \\
    Puzzle          &      No      &     No     &      Yes      &    Yes     \\
    Sample Size     &     100      &    100     &     1000      &    1000    \\
    \bottomrule
    \end{tabular}
  \caption{``Difference`` represents the absolute difference of in-sample fit between two models. ``Optimal Weight`` is the estimated weight assigned to $M_1$. ``Puzzle`` indicates whether the simple average is close to or outperforms the optimal forecast combination.}
  \label{tab:bsig}
\end{table}





+ \bf{Variance of regressors}

We keep the variance of $x_{2i}$ the same value and only increase the variance of $x_{1i}$. Then $x_{1i}$ should have a larger variance than $x_{2i}$, thus the variation of $y_i$ can be explained more by Model 1 than Model 2. This can be verified by Table \ref{tab:regvar} where $R^2$ of $M_1$ is always higher than that of $M_2$. Consequently, the in-sample performance difference between the two models is big enough to presume that all four combinations include a ``good`` Model 1 and a ``bad`` Model 2. As expected in the conjecture, Model 1 should have a higher weight, far away from 0.5, in the optimal combination. Furthermore, the forecast combination puzzle is evidenced in three of them while it is not found in the last situation, indicating that the presence of the puzzle is unclear when there is a big gap in the in-sample fit.

\begin{table}[ht]
  \centering
    \begin{tabular}{l|cccc}
    \toprule
    Change in Variance of $x_{1i}$    &  $Var(x_{1i}) = 2$   &  $Var(x_{1i}) = 4$  &  $Var(x_{1i}) = 2$  &  $Var(x_{1i}) = 4$  \\
    \midrule
    $R^2$ of $M_1$  &    0.5389    &   0.6056   &    0.3981     &   0.4947   \\
    $R^2$ of $M_2$  &    0.2899    &   0.2464   &    0.3225     &   0.2536   \\
    Difference      &    0.2490    &   0.3592   &    0.0756     &   0.2411   \\
    Optimal Weight  &     0.92     &    0.94    &     0.66      &    0.85    \\
    Puzzle          &      Yes     &    Yes     &      Yes      &     No     \\
    Sample Size     &     100      &    100     &     1000      &    1000    \\
    \bottomrule
    \end{tabular}
  \caption{``Difference`` represents the absolute difference of in-sample fit between two models. ``Optimal Weight`` is the estimated weight assigned to $M_1$. ``Puzzle`` indicates whether the simple average is close to or outperforms the optimal forecast combination.}
  \label{tab:regvar}
\end{table}







## In-sample and Out-of-sample Combination Plots {#plot}

\begin{figure}[ht]
\centering
\includegraphics[scale=0.18, angle=90]{backup_figure/betamag11.jpg}
\caption{$\beta_1$ and $\beta_2$ have the same sign but different magnitudes. The first and third columns $\beta_1=2$ and $\beta_2=4$, and the second and fourth columns $\beta_1=2$ and $\beta_2=6$. The sample size is indicated in the subtitle. Other variables remain unchanged as in the initial set-up.}
\label{fig:magnitude}
\end{figure}



\begin{figure}[ht]
\centering
\includegraphics[scale=0.18, angle=90]{backup_figure/betasign11.jpg}
\caption{$\beta_1$ and $\beta_2$ have the same magnitude but different signs, i.e. $\beta_1=-\beta_2$. The first and third columns $\beta_1=2$ and $\beta_2=-2$, and the second and fourth columns $\beta_1=4$ and $\beta_2=-4$. The sample size is indicated in the subtitle. Other variables remain unchanged as in the initial set-up.}
\label{fig:sign}
\end{figure}



\begin{figure}[ht]
\centering
\includegraphics[scale=0.18, angle=90]{backup_figure/var11.jpg}
\caption{The first and third columns $Var(x_{1i}) = 2$ and $Var(x_{2i}) = 1$. The second and fourth columns $Var(x_{1i}) = 4$ and $Var(x_{2i}) = 1$. The sample size is indicated in the subtitle. Other variables remain unchanged as in the initial set-up.}
\label{fig:variance}
\end{figure}






